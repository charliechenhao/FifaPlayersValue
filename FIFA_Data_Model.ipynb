{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df1=pd.read_csv('C:/Users/HHHH/df1.csv')\n",
    "df2=pd.read_csv('C:/Users/HHHH/df2.csv')\n",
    "df3=pd.read_csv('C:/Users/HHHH/df3.csv')\n",
    "df4=pd.read_csv('C:/Users/HHHH/df4.csv')\n",
    "df = df1.append(df2).append(df3).append(df4)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [0,1,5,9,10,42,43,44,45,46]\n",
    "df = df.drop(df.columns[cols], axis =1).dropna(subset=['Value '])\n",
    "df = df[(df['Preferred Positions '] != 'GK')].reset_index(drop=True)\n",
    "df['Height '] = df['Height '].map(lambda x: x.split(' ')[0]).astype(int)\n",
    "df['Weight '] = df['Weight '].map(lambda x: x.split(' ')[0]).astype(int)\n",
    "df['BMI'] = df['Weight '] / (df['Height ']*df['Height ']) * 10000\n",
    "df['BMI'] = df['BMI'].astype(int)\n",
    "df['Value '] = df['Value '].str.replace(\".\", \"\").str.replace(\"£\", \"\").astype(int)\n",
    "df['Wage '] = df['Wage '].str.replace(\".\", \"\").str.replace(\"£\", \"\").astype(int)\n",
    "df['Deal'] = df['Value '] / df['Wage ']\n",
    "df['Deal'] = df['Deal'].astype(int)\n",
    "df = df.reset_index(drop=True)\n",
    "print(df.shape)\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### put everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(['Value ','Wage ','Deal'], axis=1), df['Value ']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "numerical_ix = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_ix = X_train.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "t = [('cat', ce.OneHotEncoder(use_cat_names=True), categorical_ix), ('num', MinMaxScaler(), numerical_ix)]\n",
    "col_transform = ColumnTransformer(transformers=t)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "#model = GradientBoostingRegressor()\n",
    "pipeline = Pipeline(steps=[('prep',col_transform), ('m', model)])\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "grid_param = { \n",
    "            \"m__n_estimators\"      : [100, 300, 500],\n",
    "            \"m__max_features\"      : [\"auto\", \"sqrt\", \"log2\"],\n",
    "            \"m__min_samples_split\" : [2,4,8],\n",
    "            \"m__bootstrap\": [True, False],\n",
    "            }\n",
    "\n",
    "\n",
    "gd_sr = GridSearchCV(pipeline,\n",
    "                     param_grid=grid_param,\n",
    "                     #scoring = make_scorer(mean_squared_error),\n",
    "                     scoring='r2',\n",
    "                     cv=cv,\n",
    "                     n_jobs=3)\n",
    "\n",
    "# This is for GradientBoostRegressor\n",
    "# param_grid={'m__n_estimators':[100,200,500],\n",
    "#             'm__max_depth': [4, 6, 8]} \n",
    "\n",
    "# gd_sr = GridSearchCV(pipeline,\n",
    "#                      param_grid=param_grid,\n",
    "#                      #scoring = make_scorer(mean_squared_error),\n",
    "#                      scoring='r2',\n",
    "#                      cv=5,#equivalent of setting it to KFold(n_splits=5)\n",
    "#                      n_jobs=1)\n",
    "\n",
    "\n",
    "gd_sr.fit(X_train, y_train)\n",
    "\n",
    "print(gd_sr.best_params_)\n",
    "print(gd_sr.best_score_)\n",
    "print(gd_sr.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gd_sr.predict(X_test)\n",
    "from sklearn.metrics import r2_score\n",
    "test_score = r2_score(y_test, y_pred)\n",
    "print(test_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train,y_train)\n",
    "feature_name = pipeline.named_steps['prep'].transformers_[0][1].get_feature_names()\n",
    "\n",
    "num_name = numerical_ix.tolist()\n",
    "for i in range(len(num_name)):\n",
    "    feature_name.append(num_name[i])\n",
    "    i=i+1\n",
    "\n",
    "feature_importance = gd_sr.best_estimator_.named_steps['m'].feature_importances_\n",
    "output = pd.DataFrame(list(zip(feature_name,feature_importance)))\n",
    "output.columns = ['feature_name','feature_importance']\n",
    "output.sort_values(by='feature_importance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.yscale('log', nonposy='clip')\n",
    "plt.bar(feature_name, feature_importance, align='center')\n",
    "#plt.bar(feature_name, feature_name, align='center')\n",
    "#plt.xticks(range(len(feature_importance)), features, rotation='vertical')\n",
    "#plt.title('Feature importance')\n",
    "#plt.ylabel('Importance')\n",
    "#plt.xlabel('Features')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
